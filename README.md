# ğŸ’° Sistema de Pricing Ajustado al Riesgo para PYMEs

Este proyecto desarrolla una herramienta que permite a pequeÃ±as y medianas empresas calcular un tipo de interÃ©s personalizado en funciÃ³n del riesgo de impago del cliente. Se trata de un MVP funcional creado como entrega final para un MÃ¡ster en Data Science.

---

## ğŸ¯ Objetivo del Proyecto

Ofrecer una alternativa prÃ¡ctica al scoring bancario tradicional mediante:

- Modelado de la **probabilidad de impago (PD)** con datos accesibles por una pyme.
- CÃ¡lculo del **interÃ©s mÃ­nimo recomendado** ajustado al riesgo individual.
- Interfaz interactiva (opcional) para simular distintos perfiles de cliente.

---

## ğŸ“ Estructura del Proyecto

```bash

ğŸ“¦ Financiacion Clientes/                      # Carpeta raÃ­z con el nombre del proyecto
â”‚
â”œâ”€â”€ config/                            # ConfiguraciÃ³n general del proyecto
â”‚   â””â”€â”€ config.yaml                    # ParÃ¡metros como rutas, variables, hiperparÃ¡metros, etc.
â”‚
â”œâ”€â”€ data/                              # Conjunto de datos organizados por etapa
â”‚   â”œâ”€â”€ raw/                           # Datos originales sin procesar
â”‚   â”œâ”€â”€ processed/                     # Datos limpios y listos para anÃ¡lisis/modelo
â”‚   â”œâ”€â”€ validation/                    # Datos de validaciÃ³n externos o separados
â”‚   â””â”€â”€ cache/                         # Transformaciones intermedias, temporales
â”‚
â”œâ”€â”€ docs/                              # DocumentaciÃ³n tÃ©cnica y de decisiones
â”‚   â”œâ”€â”€ architecture.md                # DescripciÃ³n de la arquitectura del proyecto
â”‚   â”œâ”€â”€ decisions.md                   # Registro de decisiones tomadas
â”‚   â””â”€â”€ report.md                      # Informe final del proyecto
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter Notebooks para desarrollo y pruebas
â”‚   â”œâ”€â”€ 01_data.ipynb                  # Carga inicial de datos
â”‚   â”œâ”€â”€ 02_cleaning.ipynb              # Limpieza y tratamiento de valores anÃ³malos
â”‚   â”œâ”€â”€ 03_eda.ipynb                   # AnÃ¡lisis exploratorio de datos
â”‚   â”œâ”€â”€ 04_transformation.ipynb        # GeneraciÃ³n y transformaciÃ³n de variables
â”‚   â””â”€â”€ 05_modeling.ipynb              # Entrenamiento y evaluaciÃ³n de modelos
â”‚
â”œâ”€â”€ outputs/                           # Resultados generados por el modelo
â”‚   â”œâ”€â”€ models/                        # Archivos de modelos entrenados (.pkl, .joblib, etc.)
â”‚   â”œâ”€â”€ metrics/                       # MÃ©tricas y scores de evaluaciÃ³n
â”‚   â”œâ”€â”€ figures/                       # GrÃ¡ficos, visualizaciones exportadas
â”‚   â””â”€â”€ dashboard/                     # Informes visuales (Streamlit, Power BI, etc.)
â”‚
â”œâ”€â”€ src/                               # CÃ³digo fuente del proyecto, modular y reutilizable
â”‚   â”œâ”€â”€ __init__.py                    # Define src como paquete Python
â”‚   â”œâ”€â”€ data.py                        # Funciones para cargar datos
â”‚   â”œâ”€â”€ cleaning.py                    # Funciones de limpieza de datos
â”‚   â”œâ”€â”€ eda.py                         # Funciones de anÃ¡lisis y visualizaciÃ³n
â”‚   â”œâ”€â”€ transformation.py              # Funciones de transformaciÃ³n y selecciÃ³n de variables
â”‚   â”œâ”€â”€ modeling.py                    # Entrenamiento, evaluaciÃ³n y serializaciÃ³n de modelos
â”‚   â””â”€â”€ utils.py                       # Funciones auxiliares (logs, mÃ©tricas, formateo, etc.)
â”‚
â”œâ”€â”€ main.py                            # Script principal que ejecuta el pipeline completo
â”œâ”€â”€ README.md                          # DescripciÃ³n general y guÃ­a del proyecto
â””â”€â”€ .gitignore                         # Archivos y carpetas a excluir del control de versiones
```

---

## ğŸ“ src/ - CÃ³digo Fuente Modular

Estructura principal del cÃ³digo organizado por responsabilidades:

### ğŸ“ setup/
- **`carga_datos.py`**: funciones para cargar y guardar datasets (`cargar_csv`, `guardar_csv`).
- **(rutas.py)**: [ELIMINADO] reemplazado por el uso directo de `Path`.

### ğŸ“ limpieza/
- **`limpieza_general.py`**: funciones de limpieza como manejo de nulos, duplicados, outliers, etc.

### ğŸ“ eda/
- **`graficos.py`**: funciones para visualizaciones estÃ©ticas y reutilizables (Seaborn, Matplotlib).
- **`estadisticas.py`**: mÃ©tricas descriptivas, correlaciones, agrupaciones estadÃ­sticas.

### ğŸ“ transformacion/
- **`engineering.py`**: creaciÃ³n de variables, normalizaciÃ³n, codificaciÃ³n, binning, etc.

### ğŸ“ modelado/
- **`entrenamiento.py`**: entrenamiento de modelos de ML (sklearn, XGBoost...).
- **`evaluacion.py`**: evaluaciÃ³n de modelos con mÃ©tricas, validaciones cruzadas, ROC, etc.

### ğŸ“ utils/
- **`helpers.py`**: funciones auxiliares genÃ©ricas: mostrar lÃ­neas de un archivo, verificar dimensionalidad, cargar/guardar CSV.

---

## ğŸ“ Notebooks/

Estructura y diseÃ±o del proceso

- **`01_Setup.ipynb`**: carga inicial de datos, verificaciÃ³n de estructura y guardado.
- **`02_Limpieza.ipynb`**: limpieza de datos y validaciones.
- **`03_EDA.ipynb`**: anÃ¡lisis exploratorio de variables y patrones.
- **`04_Transformacion.ipynb`**: generaciÃ³n de nuevas variables para modelado.
- **`05_modeling.ipynb`**: entrenamiento, evaluaciÃ³n y serializaciÃ³n de modelos.

---

## ğŸ“ Datos/

OrganizaciÃ³n clara por tipo y uso:

- **Originales/**: datos sin procesar (raw)
- **Validacion/**: conjunto separado para evaluaciÃ³n del modelo
- **Trabajo/**: datos procesados para modelado
- **Caches/**: transformaciones temporales, preprocesamiento intermedio

---

## ğŸš€ Flujo de EjecuciÃ³n TÃ­pico

1. **01_Setup.ipynb**:
    - Muestra lÃ­neas del CSV
    - Carga datos
    - Verifica calidad y dimensionalidad
    - Guarda `df_trabajo.csv`

2. **02_Limpieza.ipynb**:
    - Carga datos de trabajo
    - Aplica funciones de limpieza
    - Guarda datos limpios

3. **03_EDA.ipynb**:
    - Visualiza variables numÃ©ricas/categÃ³ricas
    - Obtiene estadÃ­sticas agrupadas

4. **04_Transformacion.ipynb**:
    - Genera nuevas variables
    - Prepara datos para modelado

5. **main.py**:
    - Ejecuta el pipeline completo en orden si se desea automatizar

---

## âœ… Buenas prÃ¡cticas aplicadas

- ModularizaciÃ³n por fase
- Uso de `Path` en lugar de rutas hardcodeadas
- CentralizaciÃ³n de utilidades en `helpers.py`
- SeparaciÃ³n clara de datos, resultados, modelos y dashboards

---

## âš™ï¸ InstalaciÃ³n y EjecuciÃ³n

1. Clonar el repositorio:

```bash
git clone https://github.com/tuusuario/financiacion-clientes.git
cd financiacion-clientes
```

2. Crear entorno:

```bash
conda env create -f docs/financiacion-clientes.yml
conda activate financiacion-clientes
```

---

## ğŸ§ª TecnologÃ­as utilizadas

- Python 3.11+

'''bash
conda update -n base -c defaults conda -y
conda clean -y --all
ENTORNO="data11"
conda deactivate 
conda env remove -y -n $ENTORNO
conda create -y -n $ENTORNO python numpy pandas matplotlib seaborn statsmodels scikit-learn scipy sqlalchemy jupyter jupyter_client xgboost
conda activate $ENTORNO
conda install -y -c conda-forge plotly pyjanitor scikit-plot yellowbrick imbalanced-learn jupyter_contrib_nbextensions cloudpickle streamlit
conda install -y -c districtdatalabs yellowbrick
pip install category_encoders streamlit-echarts pipreqs
python -m ipykernel install --sys-prefix --name $ENTORNO --display-name "Python ($ENTORNO)"
jupyter kernelspec list
'''

---

## ğŸ‘¤ Autor

**Vicente Rueda**  
Proyecto Final - MÃ¡ster en Data Science  
[LinkedIn](https://linkedin.com/in/vicenterueda/)  
ğŸ“§ [vicenteruedag@gmail.com](mailto:vicenteruedag@gmail.com)

---