
import pandas as pd
from janitor import clean_names
from IPython.display import display

# -------------------------------------------------------------
# üßπ Limpieza general de variables
# -------------------------------------------------------------
# ‚û§ Est√°ndariza nombres, elimina columnas irrelevantes y transforma datos.
# -------------------------------------------------------------
def limpiar_variables_basicas(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    # 1Ô∏è‚É£ Estandarizar nombres
    df = clean_names(df)

    # 2Ô∏è‚É£ Eliminar columnas irrelevantes
    columnas_eliminar = ['id_cliente', 'id_prestamo', 'descripcion']
    df = df.drop(columns=columnas_eliminar, errors='ignore')

    # 3Ô∏è‚É£ Convertir columnas con texto a num√©ricas (extraer d√≠gitos)
    if 'antiguedad_empleo' in df.columns:
        df['antiguedad_empleo'] = (
            df['antiguedad_empleo']
            .astype(str)
            .str.extract(r'(\d+)')[0]
            .astype(float)
        )

    if 'num_cuotas' in df.columns:
        df['num_cuotas'] = (
            df['num_cuotas']
            .astype(str)
            .str.extract(r'(\d+)')[0]
            .astype(float)
        )

    return df


# -------------------------------------------------------------
# üßπ Eliminaci√≥n de registros duplicados
# -------------------------------------------------------------
# ‚û§ Elimina duplicados del DataFrame y muestra estad√≠sticas antes y despu√©s.
# -------------------------------------------------------------
def eliminar_duplicados(df):
    """
    Elimina registros duplicados del DataFrame e imprime informaci√≥n resumen.
    """
    print("\nüßπ Eliminaci√≥n de registros duplicados:")
    print(f"   ‚û§ Registros antes: {df.shape[0]}")
    print(f"   ‚û§ Duplicados detectados: {df.duplicated().sum()}")
    
    df = df.drop_duplicates().copy()
    
    print(f"   ‚û§ Registros despu√©s: {df.shape[0]}")
    return df


# =============================================================
# üß© Imputaci√≥n de nulos en variables categ√≥ricas
# -------------------------------------------------------------
# ‚û§ Imputa los valores nulos en variables categ√≥ricas seg√∫n
#    una l√≥gica definida (por ejemplo, 'OTROS' para 'empleo').
# ‚û§ La imputaci√≥n se realiza sobre el DataFrame `cat`.
# =============================================================
def imputar_nulos_categoricas(cat: pd.DataFrame) -> pd.DataFrame:
    cat = cat.copy()
    if 'empleo' in cat.columns:
        cat['empleo'] = cat['empleo'].fillna('OTROS')
    return cat


# =============================================================
# üìâ Imputaci√≥n de nulos en variables num√©ricas
# -------------------------------------------------------------
# ‚û§ Aplica imputaciones personalizadas usando un diccionario
#   de l√≥gica de negocio y estad√≠sticas b√°sicas.
# ‚û§ Cada variable tiene su propia estrategia definida.
# =============================================================
def imputar_nulos_numericas(num: pd.DataFrame) -> pd.DataFrame:
    num = num.copy()

    # Diccionario de imputaci√≥n personalizada
    imputaciones = {
        'antiguedad_empleo': lambda x: x.fillna(x.median()),
        'dti': lambda x: x.fillna(x.median()),
        'num_hipotecas': lambda x: x.fillna(0),
        'porc_tarjetas_75p': lambda x: x.fillna(0),
        'porc_uso_revolving': lambda x: x.fillna(0),
        'num_meses_desde_ult_retraso': lambda x: x.fillna(0),
        'num_cancelaciones_12meses': lambda x: x.fillna(0),
        'num_lineas_credito': lambda x: x.fillna(0),
        'num_derogatorios': lambda x: x.fillna(0)
    }

    # Aplicar imputaciones si la columna est√° presente
    for col, func in imputaciones.items():
        if col in num.columns:
            num[col] = func(num[col])

    return num


# =============================================================
# üìâ Detecci√≥n y agrupaci√≥n de categor√≠as poco representadas
# =============================================================

def detectar_atipicos_categoricos(df_cat: pd.DataFrame, umbral: float = 0.03) -> dict:
    """
    Devuelve un diccionario con categor√≠as que tienen frecuencia relativa menor al umbral.
    """
    categorias_atipicas = {}
    for col in df_cat.columns:
        frecuencias = df_cat[col].value_counts(normalize=True)
        atipicos = frecuencias[frecuencias < umbral].index.tolist()
        if atipicos:
            categorias_atipicas[col] = atipicos
    return categorias_atipicas

def agrupar_categorias_poco_frecuentes(df_cat: pd.DataFrame, categorias_a_agrup: dict, etiqueta: str = "OTROS") -> pd.DataFrame:
    """
    Agrupa categor√≠as poco frecuentes en cada variable del DataFrame bajo una etiqueta com√∫n.
    """
    df_cat = df_cat.copy()
    for col, categorias in categorias_a_agrup.items():
        df_cat[col] = df_cat[col].apply(lambda x: etiqueta if x in categorias else x)
    return df_cat


# =============================================================
# üîç An√°lisis de valores at√≠picos en variables categ√≥ricas
# =============================================================
def analizar_atipicos_categoricas(cat: pd.DataFrame, umbral_frecuencia: float = 0.03) -> None:
    """
    Analiza y muestra los valores at√≠picos en variables categ√≥ricas seg√∫n un umbral de frecuencia relativa.

    Par√°metros:
    ----------
    cat : pd.DataFrame
        Subconjunto del DataFrame original que contiene √∫nicamente variables categ√≥ricas.
    umbral_frecuencia : float, opcional
        Umbral de frecuencia relativa para considerar una categor√≠a como at√≠pica (por defecto es 0.03).
    """
    print(f"\nüìä An√°lisis de valores at√≠picos en variables categ√≥ricas (frecuencia < {umbral_frecuencia * 100:.0f}%):")
    print(f"Variables analizadas: {', '.join(cat.columns)}")
    print("-" * 100)

    for col in cat.columns:
        print(f"\nüìå Variable: '{col}'")

        # Calcular frecuencias
        frecuencia_abs = cat[col].value_counts(dropna=False)
        frecuencia_rel = cat[col].value_counts(normalize=True, dropna=False)

        # Tabla completa
        resumen = pd.DataFrame({
            "valor": frecuencia_abs.index,
            "frecuencia": frecuencia_abs.values,
            "porcentaje": (frecuencia_rel * 100).round(2)
        }).reset_index(drop=True)

        # Detectar categor√≠as at√≠picas
        categorias_atipicas = resumen[resumen["porcentaje"] < (umbral_frecuencia * 100)]

        print(f"- Total de categor√≠as: {len(resumen)}")
        if not categorias_atipicas.empty:
            print(f"- N¬∫ de categor√≠as at√≠picas detectadas: {len(categorias_atipicas)}")
        else:
            print("- No se han detectado categor√≠as at√≠picas en esta variable.")

        # Mostrar resumen completo
        print("\nüìã Tabla completa de frecuencias:")
        display(resumen)

        # Conclusi√≥n por variable
        print("üìù Conclusi√≥n:")
        match col:
            case 'empleo':
                print("‚Ä¢ Presenta miles de categor√≠as con muy baja frecuencia. Se sugiere agrupar en 'OTROS'.")
            case 'ingresos_verificados':
                print("‚Ä¢ Tiene solo 3 categor√≠as frecuentes. No requiere transformaci√≥n.")
            case 'rating':
                print("‚Ä¢ Las categor√≠as 'F' y 'G' son poco frecuentes. Podr√≠an agruparse como 'rating_bajo'.")
            case 'vivienda':
                print("‚Ä¢ Tiene una categor√≠a poco com√∫n ('OTROS'). Puede evaluarse su fusi√≥n con otra categor√≠a.")
            case 'finalidad':
                print("‚Ä¢ Presenta variedad moderada. Se evaluar√° si es necesario agrupar seg√∫n frecuencia o sem√°ntica.")
            case 'estado':
                print("‚Ä¢ Variable objetivo (target). No se modifica en esta etapa.")
            case _:
                print("‚Ä¢ No se ha definido un criterio espec√≠fico para esta variable.")

        print("\n" + "-" * 100)

    # NOTA FINAL
    print("\n================================================================================================")
    print("üìå El tratamiento de estas categor√≠as at√≠picas se realizar√° en la fase de *Feature Engineering*.")
    print("================================================================================================")



# =============================================================
# üîç An√°lisis de valores at√≠picos en variables numericas
# =============================================================
def analizar_outliers_numericos(df: pd.DataFrame, num_desv_tip: int = 3) -> None:
    """
    Analiza y reporta los valores at√≠picos en variables num√©ricas del DataFrame.
    Se consideran at√≠picos los valores fuera de ¬±num_desv_tip desviaciones t√≠picas.

    Args:
        df (pd.DataFrame): DataFrame con variables num√©ricas.
        num_desv_tip (int): N√∫mero de desviaciones t√≠picas para considerar un valor como at√≠pico.
    """
    print(f"\n\u27a4 An√°lisis de outliers usando ¬±{num_desv_tip} desviaciones t√≠picas")
    print(f"Variables analizadas: {', '.join(df.select_dtypes(include='number').columns)}")
    print("-" * 100)

    total = df.shape[0]

    for col in df.select_dtypes(include='number').columns:
        media = df[col].mean()
        std = df[col].std()
        lim_inf = media - num_desv_tip * std
        lim_sup = media + num_desv_tip * std

        valor_max = df[col].max()
        valor_min = df[col].min()

        mask_valida = df[col].between(lim_inf, lim_sup)
        fuera_rango = (~mask_valida).sum()
        valor_max_valido = df.loc[mask_valida, col].max()

        print(f"\nüìà Variable: '{col}'")
        print(f"- Media: {media:,.2f}")
        print(f"- Desviaci√≥n t√≠pica: {std:,.2f}")
        print(f"- L√≠mite inferior: {lim_inf:,.2f}")
        print(f"- L√≠mite superior: {lim_sup:,.2f}")
        print(f"- Valor m√≠nimo: {valor_min:,.2f}")
        print(f"- Valor m√°ximo: {valor_max:,.2f}")
        print(f"- Valor m√°ximo v√°lido: {valor_max_valido:,.2f}")
        print(f"- Registros fuera de rango: {fuera_rango:,} ({(fuera_rango / total) * 100:.2f}%)")
        print("-" * 100)

    print("\n\u2b50 RECOMENDACIONES GENERALES:")
    print("\u2022 Por defecto se recomienda usar ¬±3 desviaciones t√≠picas para detectar outliers.")
    print("\u2022 Este criterio es apropiado para distribuciones normales.")
    print("\n\u26a0 Para distribuciones no normales, considerar:")
    print("  - IQR: valores fuera de Q1-1.5√óIQR y Q3+1.5√óIQR.")
    print("  - Boxplot, z-score robusto, percentiles.")
    print("\nüìÑ Recomendaci√≥n para este proyecto:")
    print("  1. Empezar con ¬±3œÉ como criterio.")
    print("  2. Complementar con visualizaciones en el EDA (boxplots, histogramas).")